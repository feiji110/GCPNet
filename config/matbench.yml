config:
  project_name: "matbench"                 # Name of the project.
  net: "GCPNet"                          # Name of the network
  output_dir: "./output"                 # Output directory for the training model
  self_loop: True                        # Whether to add self loop to the graph
  n_neighbors: 12                        #. of nearest neighbors for the atom
  debug: False                           # Whether to run in debug mode: print net and optimizer 

netAttributes:
  firstUpdateLayers: 4                   # #. of layers for updating the first-order update 
  secondUpdateLayers: 4                  # #. of layers for updating the second-order update
  atom_input_features: 105               # dimensions of atom features:  should be [dim(atom_init) + n_neighbors + 1]       
  edge_input_features: 50                # RBF dimensions of the edge feature
  triplet_input_features: 40             # dimensions of triplet features
  embedding_features: 64                 # #. of embedding features
  hidden_features: 32                    # #. of hidden features
  output_features: 1                     # #. of output features
  min_edge_distance: 0.0                 # minimum distance for the bond
  max_edge_distance: 8.0                 # maximum distance for the bond
  link: "identity"                       # link function for the output layer: surport "identity", "exp", "sigmoid"
  batch_size: 64                         # batch size 
  num_workers: 0                         # #. of workers for data loading
  dropout_rate: 0.0                      # dropout rate for GCAO
hyperParameters:
  lr: 0.001                              # learning rate
  optimizer: "AdamW"                     # optimizer: support "AdamW", "Adam", "SGD"
  optimizer_args:                        # optimizer arguments
    weight_decay: 0.00001                # weight decay
  scheduler: "ReduceLROnPlateau"         # scheduler: support "ReduceLROnPlateau", "CosineAnnealingLR", "CosineAnnealingWarmRestarts"
  scheduler_args:                        # scheduler arguments
    mode: "min"
    factor: 0.8
    patience: 10
    min_lr: 0.00001
    threshold: 0.0002
  seed: 666                              # random seed
  epochs: 150                            # #. of epochs
  patience: 30                           # patience for early stopping  

data:
  points: all                            # points for the dataset: support "all", and a number smaller than the #. of data points
  dataset_path: './data'                 # path for all datasets
  dataset_name: 'matbench'                     # name of the dataset, support '2d','cubic', 'mp18','pt', 'mof' etc. 
  target_name: 'property'                # name of the target, support 'property', 'formation_energy_per_atom'
  pin_memory: True                       # whether to pin memory for data loading

predict:
  model_path: 'model.pt'                 # path for the model
  output_path: 'output.csv'              # path for the predict output


wandb:
  log_enable: True                       # whether to enable wandb, support True, False
  sweep_count: 100   #                       # integer value to the count parameter to set the maximum number of runs to try.
  entity: "19831122880"                  # entity name for wandb,see https://docs.wandb.ai/guides/sweeps/start-sweep-agents
  sweep_args:                            # sweep arguments
    method: bayes    #   random  # 三种搜索方式
    metric:
      goal: minimize
      name: test_mae_mean
    parameters:
      project_name:
        value: "matbench" #  这个参数目前没用？？
      epochs:
        value: 100   # 
      optimizer:
        values: ['Adam', 'AdamW'] # delete'SGD',
      lr: 
        distribution: log_uniform_values
        min: 0.0001
        max: 0.09
      firstUpdateLayers:
        values: [1, 2, 3]
      secondUpdateLayers:
        values: [1, 2, 3]
      hidden_features:
        values: [16, 32, 64, 96]
      batch_size:
        values: [32, 64, 96, 100]